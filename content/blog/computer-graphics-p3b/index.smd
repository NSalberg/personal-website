---
.title = "Computer Graphics Project 3B - The Raytracer",
.date = @date("2025-11-01:00:00"),
.author = "Nathan Salberg",
.layout = "post.shtml",
.draft = false,
--- 

This is a continuation of the previous assignment - the ray-tracer. In addition to the work completed in the previous assignment I was tasked with adding additional features to support triangle renderings and parsing.

To start I added jitterd sampling. The scene parser now has a new arguement, `samples_per_pixel`. 
Then, instead of sampling a single ray for each pixel in the output image, we jitter the ray casts' direction randomly, sampling `samples_per_pixel` times and averaging the results.

```zig
for (0..self.samples_per_pixel) |_| {
    const ray = self.getRay(@intCast(i), @intCast(line_number));
    color += s.shadeRay(ray, self.max_depth);
}
color = color * vec3.splat(self.samples_per_pix_inv.?);

image.setPixel(@intCast(i), @intCast(line_number), color);
```
[spheres-2-jittered]($image.asset("spheres2-no-refraction.png").size(0,400))
[spheres-2-no-jitter]($image.asset("spheres2-no-jitter.png").size(0,400))

Then I set out on getting refraction to work. 

```zig
if (vec3.magnitude2(material.transmissive_color) > 0.001) {
    const entering = vec3.dot(ray.dir, n) < 0;
    const etai_over_etat = if (entering)
        1.0 / material.index_of_refraction // air -> material
    else
        material.index_of_refraction; // material -> air

    const normal = if (entering) n else -n;

    const refraction = vec3.refract(ray.dir, normal, etai_over_etat);
    const bounce_color = material.transmissive_color * self.shadeRay(.{ .dir = refraction, .origin = p + refraction * vec3.splat(0.001) }, bounces - 1);
    color += bounce_color;
}
```


After I was satified with my refraction implemention, I worked on implementing triangles.


Rendering triangles requires us to create an abstraction over the 'hittable' objects in the scene. 
Each hittable object ino our scene will implement a `hit(object: Object, ray: main.Ray, ray_tmin: f64, ray_tmax: f64) ?main.HitRecord` function which returns null if no hit occurs or a struct called `hitRecord` with information about the hit, like the normal, distance, and material.

To create a sort of  'base class' in zig we can use a union enum. 
This enum defines a hit function which all members of the union will have to implement. The function `hit()` just calls the hit function for the corresponing `Object` it was called on

```zig 
pub const Object = union(enum) {
    sphere: Sphere,
    triangle: Triangle,
    normal_triangle: NormalTriangle,

    pub fn hit(object: Object, ray: main.Ray, ray_tmin: f64, ray_tmax: f64) ?main.HitRecord {
        return switch (object) {
            inline else => |obj| obj.hit(ray, ray_tmin, ray_tmax),
        };
    }
}
```

Then, when parsing the scene file we add all spheres, and triangles to an `ArrayList` of type `Object`


`try scene.objects.append(allocator, objects.Object{ .triangle = tri });`

// mention triangle hit? 

Finally, I parallelized my ray tracer by dividing each line of the ray-tracer across a thread pool.
Zig makes this pretty easy. First we create our thread pool         
```zig
var pool: std.Thread.Pool = undefined;
try pool.init(.{
.allocator = allocator,
});
defer pool.deinit();
```
The defer line automatcally calls join on all the threads when we exit the current scope. 
Then for each scan line we can give that task to one of the threads in our thread pool
```zig
var wg: std.Thread.WaitGroup = .{};
for (0..img_height) |j| {
    pool.spawnWg(&wg, Camera.scanLine, .{ self, j, &output_img, s, line_pb });
```

// show speed increase





**Code**



**Additional Scenes**





